{"ast":null,"code":"\"use strict\";\n\nvar _objectSpread = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/objectSpread\");\nvar _classCallCheck = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/classCallCheck\");\nvar _createClass = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createClass\");\nvar _possibleConstructorReturn = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/possibleConstructorReturn\");\nvar _getPrototypeOf = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/getPrototypeOf\");\nvar _inherits = require(\"F:\\\\programnodejs\\\\project\\\\client\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/inherits\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketReadStream = void 0;\nvar stream_1 = require(\"stream\");\nvar error_1 = require(\"../error\");\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n * @public\n */\nvar GridFSBucketReadStream = /*#__PURE__*/function (_stream_1$Readable) {\n  _inherits(GridFSBucketReadStream, _stream_1$Readable);\n  /** @internal\n   * @param chunks - Handle for chunks collection\n   * @param files - Handle for files collection\n   * @param readPreference - The read preference to use\n   * @param filter - The filter to use to find the file document\n   */\n  function GridFSBucketReadStream(chunks, files, readPreference, filter, options) {\n    var _this;\n    _classCallCheck(this, GridFSBucketReadStream);\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(GridFSBucketReadStream).call(this));\n    _this.s = {\n      bytesToTrim: 0,\n      bytesToSkip: 0,\n      bytesRead: 0,\n      chunks: chunks,\n      expected: 0,\n      files: files,\n      filter: filter,\n      init: false,\n      expectedEnd: 0,\n      options: _objectSpread({\n        start: 0,\n        end: 0\n      }, options),\n      readPreference: readPreference\n    };\n    return _this;\n  }\n  /**\n   * Reads from the cursor and pushes to the stream.\n   * Private Impl, do not call directly\n   * @internal\n   */\n  _createClass(GridFSBucketReadStream, [{\n    key: \"_read\",\n    value: function _read() {\n      var _this2 = this;\n      if (this.destroyed) return;\n      waitForFile(this, function () {\n        return doRead(_this2);\n      });\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param start - 0-based offset in bytes to start streaming from\n     */\n  }, {\n    key: \"start\",\n    value: function start() {\n      var _start = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n      throwIfInitialized(this);\n      this.s.options.start = _start;\n      return this;\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param end - Offset in bytes to stop reading at\n     */\n  }, {\n    key: \"end\",\n    value: function end() {\n      var _end = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n      throwIfInitialized(this);\n      this.s.options.end = _end;\n      return this;\n    }\n    /**\n     * Marks this stream as aborted (will never push another `data` event)\n     * and kills the underlying cursor. Will emit the 'end' event, and then\n     * the 'close' event once the cursor is successfully killed.\n     *\n     * @param callback - called when the cursor is successfully closed or an error occurred.\n     */\n  }, {\n    key: \"abort\",\n    value: function abort(callback) {\n      var _this3 = this;\n      this.push(null);\n      this.destroyed = true;\n      if (this.s.cursor) {\n        this.s.cursor.close(function (error) {\n          _this3.emit(GridFSBucketReadStream.CLOSE);\n          callback && callback(error);\n        });\n      } else {\n        if (!this.s.init) {\n          // If not initialized, fire close event because we will never\n          // get a cursor\n          this.emit(GridFSBucketReadStream.CLOSE);\n        }\n        callback && callback();\n      }\n    }\n  }]);\n  return GridFSBucketReadStream;\n}(stream_1.Readable);\nexports.GridFSBucketReadStream = GridFSBucketReadStream;\n/**\n * An error occurred\n * @event\n */\nGridFSBucketReadStream.ERROR = 'error';\n/**\n * Fires when the stream loaded the file document corresponding to the provided id.\n * @event\n */\nGridFSBucketReadStream.FILE = 'file';\n/**\n * Emitted when a chunk of data is available to be consumed.\n * @event\n */\nGridFSBucketReadStream.DATA = 'data';\n/**\n * Fired when the stream is exhausted (no more data events).\n * @event\n */\nGridFSBucketReadStream.END = 'end';\n/**\n * Fired when the stream is exhausted and the underlying cursor is killed\n * @event\n */\nGridFSBucketReadStream.CLOSE = 'close';\nfunction throwIfInitialized(stream) {\n  if (stream.s.init) {\n    throw new error_1.MongoGridFSStreamError('Options cannot be changed after the stream is initialized');\n  }\n}\nfunction doRead(stream) {\n  if (stream.destroyed) return;\n  if (!stream.s.cursor) return;\n  if (!stream.s.file) return;\n  stream.s.cursor.next(function (error, doc) {\n    if (stream.destroyed) {\n      return;\n    }\n    if (error) {\n      stream.emit(GridFSBucketReadStream.ERROR, error);\n      return;\n    }\n    if (!doc) {\n      stream.push(null);\n      process.nextTick(function () {\n        if (!stream.s.cursor) return;\n        stream.s.cursor.close(function (error) {\n          if (error) {\n            stream.emit(GridFSBucketReadStream.ERROR, error);\n            return;\n          }\n          stream.emit(GridFSBucketReadStream.CLOSE);\n        });\n      });\n      return;\n    }\n    if (!stream.s.file) return;\n    var bytesRemaining = stream.s.file.length - stream.s.bytesRead;\n    var expectedN = stream.s.expected++;\n    var expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);\n    if (doc.n > expectedN) {\n      return stream.emit(GridFSBucketReadStream.ERROR, new error_1.MongoGridFSChunkError(\"ChunkIsMissing: Got unexpected n: \".concat(doc.n, \", expected: \").concat(expectedN)));\n    }\n    if (doc.n < expectedN) {\n      return stream.emit(GridFSBucketReadStream.ERROR, new error_1.MongoGridFSChunkError(\"ExtraChunk: Got unexpected n: \".concat(doc.n, \", expected: \").concat(expectedN)));\n    }\n    var buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n    if (buf.byteLength !== expectedLength) {\n      if (bytesRemaining <= 0) {\n        return stream.emit(GridFSBucketReadStream.ERROR, new error_1.MongoGridFSChunkError(\"ExtraChunk: Got unexpected n: \".concat(doc.n, \", expected file length \").concat(stream.s.file.length, \" bytes but already read \").concat(stream.s.bytesRead, \" bytes\")));\n      }\n      return stream.emit(GridFSBucketReadStream.ERROR, new error_1.MongoGridFSChunkError(\"ChunkIsWrongSize: Got unexpected length: \".concat(buf.byteLength, \", expected: \").concat(expectedLength)));\n    }\n    stream.s.bytesRead += buf.byteLength;\n    if (buf.byteLength === 0) {\n      return stream.push(null);\n    }\n    var sliceStart = null;\n    var sliceEnd = null;\n    if (stream.s.bytesToSkip != null) {\n      sliceStart = stream.s.bytesToSkip;\n      stream.s.bytesToSkip = 0;\n    }\n    var atEndOfStream = expectedN === stream.s.expectedEnd - 1;\n    var bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;\n    if (atEndOfStream && stream.s.bytesToTrim != null) {\n      sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;\n    } else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {\n      sliceEnd = bytesLeftToRead;\n    }\n    if (sliceStart != null || sliceEnd != null) {\n      buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);\n    }\n    stream.push(buf);\n    return;\n  });\n}\nfunction init(stream) {\n  var findOneOptions = {};\n  if (stream.s.readPreference) {\n    findOneOptions.readPreference = stream.s.readPreference;\n  }\n  if (stream.s.options && stream.s.options.sort) {\n    findOneOptions.sort = stream.s.options.sort;\n  }\n  if (stream.s.options && stream.s.options.skip) {\n    findOneOptions.skip = stream.s.options.skip;\n  }\n  stream.s.files.findOne(stream.s.filter, findOneOptions, function (error, doc) {\n    if (error) {\n      return stream.emit(GridFSBucketReadStream.ERROR, error);\n    }\n    if (!doc) {\n      var identifier = stream.s.filter._id ? stream.s.filter._id.toString() : stream.s.filter.filename;\n      var errmsg = \"FileNotFound: file \".concat(identifier, \" was not found\");\n      // TODO(NODE-3483)\n      var err = new error_1.MongoRuntimeError(errmsg);\n      err.code = 'ENOENT'; // TODO: NODE-3338 set property as part of constructor\n      return stream.emit(GridFSBucketReadStream.ERROR, err);\n    }\n    // If document is empty, kill the stream immediately and don't\n    // execute any reads\n    if (doc.length <= 0) {\n      stream.push(null);\n      return;\n    }\n    if (stream.destroyed) {\n      // If user destroys the stream before we have a cursor, wait\n      // until the query is done to say we're 'closed' because we can't\n      // cancel a query.\n      stream.emit(GridFSBucketReadStream.CLOSE);\n      return;\n    }\n    try {\n      stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);\n    } catch (error) {\n      return stream.emit(GridFSBucketReadStream.ERROR, error);\n    }\n    var filter = {\n      files_id: doc._id\n    };\n    // Currently (MongoDB 3.4.4) skip function does not support the index,\n    // it needs to retrieve all the documents first and then skip them. (CS-25811)\n    // As work around we use $gte on the \"n\" field.\n    if (stream.s.options && stream.s.options.start != null) {\n      var skip = Math.floor(stream.s.options.start / doc.chunkSize);\n      if (skip > 0) {\n        filter['n'] = {\n          $gte: skip\n        };\n      }\n    }\n    stream.s.cursor = stream.s.chunks.find(filter).sort({\n      n: 1\n    });\n    if (stream.s.readPreference) {\n      stream.s.cursor.withReadPreference(stream.s.readPreference);\n    }\n    stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n    stream.s.file = doc;\n    try {\n      stream.s.bytesToTrim = handleEndOption(stream, doc, stream.s.cursor, stream.s.options);\n    } catch (error) {\n      return stream.emit(GridFSBucketReadStream.ERROR, error);\n    }\n    stream.emit(GridFSBucketReadStream.FILE, doc);\n    return;\n  });\n}\nfunction waitForFile(stream, callback) {\n  if (stream.s.file) {\n    return callback();\n  }\n  if (!stream.s.init) {\n    init(stream);\n    stream.s.init = true;\n  }\n  stream.once('file', function () {\n    callback();\n  });\n}\nfunction handleStartOption(stream, doc, options) {\n  if (options && options.start != null) {\n    if (options.start > doc.length) {\n      throw new error_1.MongoInvalidArgumentError(\"Stream start (\".concat(options.start, \") must not be more than the length of the file (\").concat(doc.length, \")\"));\n    }\n    if (options.start < 0) {\n      throw new error_1.MongoInvalidArgumentError(\"Stream start (\".concat(options.start, \") must not be negative\"));\n    }\n    if (options.end != null && options.end < options.start) {\n      throw new error_1.MongoInvalidArgumentError(\"Stream start (\".concat(options.start, \") must not be greater than stream end (\").concat(options.end, \")\"));\n    }\n    stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n    stream.s.expected = Math.floor(options.start / doc.chunkSize);\n    return options.start - stream.s.bytesRead;\n  }\n  throw new error_1.MongoInvalidArgumentError('Start option must be defined');\n}\nfunction handleEndOption(stream, doc, cursor, options) {\n  if (options && options.end != null) {\n    if (options.end > doc.length) {\n      throw new error_1.MongoInvalidArgumentError(\"Stream end (\".concat(options.end, \") must not be more than the length of the file (\").concat(doc.length, \")\"));\n    }\n    if (options.start == null || options.start < 0) {\n      throw new error_1.MongoInvalidArgumentError(\"Stream end (\".concat(options.end, \") must not be negative\"));\n    }\n    var start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n    cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n    stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n    return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n  }\n  throw new error_1.MongoInvalidArgumentError('End option must be defined');\n}","map":null,"metadata":{},"sourceType":"script"}